
experiment:
    description: 'This pilot experiment will consist of a maze navigation with subsequent 2AFC task. Keypecking will be rewarded and food quantity maximisation will be set against key distance/effort/reachability. First, feeder will be consistently preceeded by stimulus and subjects develop autoshaping, pecking on stimulus previous to feeder. Then, a second alternative key is presented with (better or worse?) reward and subjects learn to discriminate optimal choice. Next, prefered key varies in depth, and big-reward choice becomes suboptimal behind the reachability threshold. NOTE: safe option remains always on baseline depth. Result: Optimality tipping point is *depth* dependent. On the second part of the experiment, subjects will be wearing a robotic arm (group dependent). First, subjects only have to habituate on wearing the robotic arm by navigating the maze and pecking prefered key of equally available options. Next, keys will be lowered from beak to arm height and moved behind reachability threshold from training2, subjects will learn to press keys with robotic arm. NOTE: active training may be needed if coordinated movement missing. Next, best attractive key varies in depth, and big reward choice becomes suboptimal behind new reachability threshold. NOTE: arm length is not necessarily reachability space, as distant targets are difficult to get with tool. Result: Optimality tipping point is *depth* dependent AND *bodily* dependent. Last, subjects change the robotic arm group and repeat the last discrimination task. NOTE: group 1 changes from long to short (easy habituation less reachability) and group 2 changes from short to long (difficult habituation more reachability). Result: Optimality tipping point is adapted to new arm, but still trying for old arm. Result 2: Change in reachability is not by arm per se but by length of robotic arm.'
    
    groups:
        group1: long arm # TBD
        group2: short arm # TBD
        # introduction second key better/worse
        # color-reward pairing
        # big/small reward difference
        
    conditions:
        training_autoshaping: 'Subjects autoshape on single key and start pecking for reward'
        training_quantity: 'Subjects discriminate between two keys and maximize reward quantity (feeding time)'
        training_optimal: 'Subjects discriminate keys based on depth, i.e. reachability'
        test_habituation: 'Subjects habituate to wear robotic arm on training_quantity'
        test_tooluse: 'Subjects learn to use robotic arm to press distant key. Keys are lower and first touched by mistake.'
        test_embodiment: 'Subjects replicate training_optimal descrimination on reachability'
        transfer_armlength: 'Subjects replicate test_embodiment descrimination with new arm length'
        transfer_noarm: 'Subjects replicate training_optimal after X time'
        transfer_: 'Subjects replicate test_embodiment after X time'
    
    # AUTOSHAPING: Subjects autoshape on single key and start pecking for reward
    trial_training_autoshaping:
        trials_per_session: 10 # habituation_time + run + repetitions
        habituation_time: 120 # seconds between handling and maze run
        repetitions: True # number of rewarded pecks per run. In autoshaping until timeout
        timeout: 120 # seconds before inactivity trial end. In autoshaping = trial length
        optimal_reward: 3 # feeding time in seconds. In autoshaping: key 2sec, feeder 3sec, key 2sec ... 
        optimal_key_position: right/left # pseudorandomized
        optimal_key_depth: 0 # mm from plexiglas
        optimal_stimuluscolor: "lime" # see visual pigments in chicken and pigeon (Govardovskii & Zueva, 1977)
        suboptimal_reward: # feeding time in seconds. Not used in autoshaping
        suboptimal_key_depth: 300 # obvious out of reach distance, not in use during autoshaping
        suboptimal_stimuluscolor: "black" # not used in autoshaping
        min_sessions: 10 # minimum number of sessions before testing for criterion
        criterion: 80 # percentage of feedings per session preceeded by key peck# key pecked 

    # QUANTITY: Subjects discriminate between two keys and maximize reward quantity (feeding time)
    trial_training_quantity:
        trials_per_sessoin: 10 # habituation_time + run + repetitions
        habituation_time: 120 # seconds between handling and maze run
        repetitions: 5 # number of rewarded pecks per run.
        timeout: 120 # seconds before inactivity trial end.
        optimal_reward: 3 # feeding time in seconds. 
        optimal_key_position: right/left # pseudorandomized
        optimal_key_depth: 0 # mm from plexiglas. 
        optimal_stimuluscolor: "lime" # see visual pigments in chicken and pigeon (Govardovskii & Zueva, 1977) 
        suboptimal_reward: 1 # feeding time in seconds. Not used in autoshaping
        suboptimal_key_depth: 0 # obvious out of reach distance, not in use during autoshaping
        suboptimal_stimuluscolor: "purple" # see color list here: https://www.w3.org/TR/css-color-3/
        min_sessions: 10 # minimum number of sessions before testing for criterion
        criterion: 80 # percentage of feedings per session preceeded by key peck# key pecked 

    # QUANTITY: Subjects discriminate between two keys and maximize reward quantity (feeding time)
    trial_training_quantity:
        trials_per_sessoin: 10 # habituation_time + run + repetitions
        habituation_time: 120 # seconds between handling and maze run
        repetitions: 5 # number of rewarded pecks per run.
        timeout: 120 # seconds before inactivity trial end.
        optimal_reward: 3 # feeding time in seconds. 
        optimal_key_position: right/left # pseudorandomized
        optimal_key_depth: [0, 10, 20, 30, 40, 50] # mm from plexiglas. 
        optimal_stimuluscolor: "lime" # see visual pigments in chicken and pigeon (Govardovskii & Zueva, 1977)
        suboptimal_reward: 1 # feeding time in seconds. Not used in autoshaping
        suboptimal_key_depth: 0 # obvious out of reach distance, stays put!
        suboptimal_stimuluscolor: "purple" # not used in autoshaping
        min_sessions: 10 # minimum number of sessions before testing for criterion
        criterion: 80 # percentage of feedings per session preceeded by key peck# key pecked 


    # This trial will be embedded in a session within a condition...
    trial:
        habituation_time: 10 # in seconds
        repetitions: 5 # number of repetitions per trial
        timeout: 300 # in seconds
        optimal_reward: 3 # feeding time in seconds
        suboptimal_reward: 0.1 # feeding time in seconds
        optimal_stimuluscolor: "lime" # see color list here: https://www.w3.org/TR/css-color-3/
        suboptimal_stimuluscolor: "purple"
        
        
        
    
